# ğŸ¬ Netflix Streaming Data Transformation using dbt & Snowflake

![dbt](https://img.shields.io/badge/dbt-v1.8+-orange?logo=dbt&logoColor=white)
![Snowflake](https://img.shields.io/badge/Snowflake-Data%20Warehouse-blue?logo=snowflake&logoColor=white)
![AWS S3](https://img.shields.io/badge/AWS-S3-232F3E?logo=amazon-aws&logoColor=white)
![Status](https://img.shields.io/badge/Status-Completed-success)


## ğŸ“˜ Project Overview

This project demonstrates an **end-to-end data transformation pipeline** for Netflix streaming analytics using **dbt** and **Snowflake**. Raw data from **AWS S3** is ingested into Snowflake, where dbt performs all transformations to produce **analytics-ready, governed data models**.


## âš™ï¸ Tech Stack

| Tool / Service | Purpose |
|------|----------|
| **dbt (data build tool)** | Transformation, testing, and data modeling |
| **Snowflake** | Cloud data warehouse for scalable compute & storage |
| **AWS S3** | Raw data source for ingestion |
| **SQL & Jinja** | Transformation logic and dynamic templating |
| **Git / GitHub** | Version control and project documentation |


## ğŸ§© Data Pipeline Architecture

The project follows a **modern analytics engineering pattern** with a clear separation between layers: <br/>
AWS S3 â†’ Snowflake (Raw) â†’ dbt Staging â†’ dbt Intermediate (Dimension / Fact) â†’ Data Marts â†’ BI Layer


## ğŸ§± Project Structure
. <br/>
â”œâ”€â”€ analyses/ # Analytical SQL scripts <br/>
â”œâ”€â”€ macros/ # Custom tests for data consistency <br/>
â”œâ”€â”€ models/ <br/>
â”‚ â”œâ”€â”€ dim/ # Dimesional tables with business logic <br/>
| â”œâ”€â”€ fct/ # Fact tables <br/>
â”‚ â”œâ”€â”€ mart/ # Dedicated tables for analytics <br/>
| â””â”€â”€ staging/ # Views from raw data <br/>
â”œâ”€â”€ seeds/ # Static CSVs for lookup data <br/>
â”œâ”€â”€ snapshots/ # SCD management <br/>
â”œâ”€â”€ tests/ # Generic and singular data tests <br/>
â”œâ”€â”€ dbt_project.yml <br/>
â””â”€â”€ packages.yml <br/>


## ğŸ” Core dbt Concepts Showcased

### âš™ï¸ **Materializations**
Experimented with `view`, `table`, `ephemeral`, and `incremental` materializations to balance cost and performance.

### âœ… **Testing and Data Quality**
Used:
- **Generic tests:** `unique`, `not_null`, `relationships`, `accepted_values`
- **Singular tests:** Custom SQL assertions for business logic

### ğŸ•’ **Snapshots (SCD Type 2)**
Implemented snapshots for **Slowly Changing Dimensions** to retain historical subscription and content data.

### ğŸ“¦ **dbt Packages**
Integrated:
- `dbt_utils` for macros and schema testing  
- `dbt_expectations` for extended data validation

### ğŸŒ± **Seeds**
Loaded static CSVs directly with dbt â€” ideal for reference tables without external sources.

### ğŸ§© **Macros & Jinja**
Developed reusable macros for **dynamic SQL generation** and **templated transformations**, ensuring modularity and maintainability.

### ğŸ“š **Documentation**
Generated with:
```bash
dbt docs generate
dbt docs serve
